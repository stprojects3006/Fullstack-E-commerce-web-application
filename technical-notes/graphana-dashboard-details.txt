Absolutely! Here's how you can achieve a comprehensive Grafana dashboard for your microservices, focusing on:
------------------------------------------------------------------------
1. Request/response latency
2. Service health (up/down)
3. Downtime duration and crash analysis
4. Request/response rates
5. Drill-down into downtime events

1. Metrics You Need
------------------------------------------------------------------------
Latency:
    http_server_requests_seconds (from Spring Boot Micrometer/Prometheus)
    probe_duration_seconds (from Blackbox Exporter)

Service Health:
    up (Prometheus target status: 1=up, 0=down)

Request/Response Rate:
    http_server_requests_seconds_count

Downtime Analysis:
    up over time (with annotations for down events)
    process_start_time_seconds (when service restarts)

Crash Details:
    Use logs, process_start_time_seconds, and alert annotations

2. Ready-to-Import Grafana Dashboard JSON
------------------------------------------------------------------------
Below is a dashboard JSON you can import directly into Grafana.
(You may need to adjust datasource name to match your Prometheus data source, usually Prometheus.)
<details>
<summary>Click to expand the dashboard JSON</summary>

```
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": "-- Grafana --",
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "gnetId": null,
  "graphTooltip": 1,
  "iteration": 162,
  "links": [],
  "panels": [
    {
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 0 },
      "id": 1,
      "options": {
        "legend": { "displayMode": "table", "placement": "bottom" }
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(http_server_requests_seconds_bucket[5m])) by (le, service))",
          "legendFormat": "{{service}}",
          "refId": "A"
        }
      ],
      "title": "95th Percentile Request Latency (s)",
      "type": "timeseries"
    },
    {
      "datasource": "Prometheus",
      "fieldConfig": { "defaults": {}, "overrides": [] },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 0 },
      "id": 2,
      "options": {
        "legend": { "displayMode": "table", "placement": "bottom" }
      },
      "targets": [
        {
          "expr": "sum by (service) (rate(http_server_requests_seconds_count[5m]))",
          "legendFormat": "{{service}}",
          "refId": "A"
        }
      ],
      "title": "Request Rate (req/s)",
      "type": "timeseries"
    },
    {
      "datasource": "Prometheus",
      "fieldConfig": { "defaults": {}, "overrides": [] },
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 8 },
      "id": 3,
      "options": {
        "legend": { "displayMode": "table", "placement": "bottom" }
      },
      "targets": [
        {
          "expr": "up",
          "legendFormat": "{{instance}}",
          "refId": "A"
        }
      ],
      "title": "Service Health (Up/Down)",
      "type": "state-timeline"
    },
    {
      "datasource": "Prometheus",
      "fieldConfig": { "defaults": {}, "overrides": [] },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 8 },
      "id": 4,
      "options": {
        "legend": { "displayMode": "table", "placement": "bottom" }
      },
      "targets": [
        {
          "expr": "changes(up[1d])",
          "legendFormat": "{{instance}}",
          "refId": "A"
        }
      ],
      "title": "Service Restarts/Crashes (last 24h)",
      "type": "timeseries"
    },
    {
      "datasource": "Prometheus",
      "fieldConfig": { "defaults": {}, "overrides": [] },
      "gridPos": { "h": 8, "w": 24, "x": 0, "y": 16 },
      "id": 5,
      "options": {
        "legend": { "displayMode": "table", "placement": "bottom" }
      },
      "targets": [
        {
          "expr": "probe_duration_seconds{job=\"blackbox-http\"}",
          "legendFormat": "{{instance}}",
          "refId": "A"
        }
      ],
      "title": "Frontend/HTTP Probe Latency (Blackbox Exporter)",
      "type": "timeseries"
    }
  ],
  "refresh": "10s",
  "schemaVersion": 37,
  "style": "dark",
  "tags": ["latency", "health", "microservices"],
  "templating": { "list": [] },
  "time": { "from": "now-6h", "to": "now" },
  "timepicker": {},
  "timezone": "",
  "title": "Microservices Health & Latency Overview",
  "uid": "microservices-latency-health",
  "version": 1,
  "weekStart": ""
}
</details>

3. How to Import This Dashboard
------------------------------------------------------------------------
1. Copy the JSON above (expand the details section).
2. In Grafana, go to the left menu â†’ Dashboards â†’ Import.
3. Paste the JSON into the "Import via panel json" box.
4. Select your Prometheus data source.
5. Click Import.

4. What You'll See
------------------------------------------------------------------------
- 95th Percentile Request Latency: For each service (from Micrometer/Prometheus).
- Request Rate: Requests per second per service.
- Service Health: Timeline showing up/down state for each service (with downtime gaps).
- Service Restarts/Crashes: Number of times each service went up/down in the last 24h.
- Frontend/HTTP Probe Latency: Blackbox Exporter probe times for your frontend and key endpoints.

5. Drill-Down and Crash Analysis
------------------------------------------------------------------------
- Click on downtime events in the "Service Health" panel to see when a service went down and came back up.
- Correlate spikes in latency or drops in request rate with downtime events.
- Use the "Service Restarts/Crashes" panel to see which services are unstable.
- For crash reasons, check logs in Docker (`docker-compose logs <service>`) and consider adding alerting rules in Prometheus for `up == 0` or high error rates.

6. Customizing Further
------------------------------------------------------------------------
- Add more panels for error rates:
  `sum(rate(http_server_requests_seconds_count{status!~"2.."}[5m])) by (service)`
- Add alert rules in Prometheus for `up == 0` or high latency.
- Use [Loki](https://grafana.com/oss/loki/) for log aggregation and link logs to downtime events.

Let me know if you want:
- A dashboard for a specific service
- More advanced drill-downs
- Example Prometheus alert rules
- Help with Grafana alerting or log integration

I'm here to help you get the best observability for your stack! ðŸš€